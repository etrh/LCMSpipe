---
title: "Pipeline for Analysis of Metabolomics Data in R"
author: "Ashkan Zareie"
date: "August-September 2017"
output: html_document
---
  
  
On UNIX-based systems you will first need to ensure that the following requirements are installed:  
  `sudo apt-get install -y libxml2-dev libcurl4-openssl-dev libssl-dev netcdf-bin libnetcdf-dev gfortran libblas-dev liblapack-dev libpcre++-dev liblzma-dev libbz2-dev libgtk2.0-dev bwidget libglu1-mesa-dev freeglut3-dev mesa-common-dev default-jre default-jdk libmariadbclient-dev libmariadb-client-lgpl-dev texinfo texlive`
  
  
```{r Setup, include=FALSE}
# # # # - - - - IMPORTANT: make sure you have the latest version of R installed - - - - # # # #

# system("echo 'R_MAX_NUM_DLLS=500' > $HOME/.Renviron") ### do this only if you get the 'Maximal number of DLLs reached' error

update.packages()
#update.packages(repos = "https://cloud.r-project.org/")

if(!require(pacman)){install.packages("pacman")}

source("http://bioconductor.org/biocLite.R")
if(!require(MSnbase)){biocLite("MSnbase", dependencies = TRUE)}
if(!require(xcms)){biocLite("xcms", dependencies = TRUE)}
if(!require(CAMERA)){biocLite("CAMERA", dependencies = TRUE)}
if(!require(IPO)){biocLite("IPO", dependencies = TRUE)}

# Development versions of MSnbase and xcms
#   biocLite("sneumann/mzR")
#   biocLite("lgatto/MSnbase")
#   devtools::install_github("sneumann/xcms", ref = "xcms3")

pacman::p_install("Rserve", "som", "ROCR", "RJSONIO", "Cairo", 
                  "pheatmap", "lattice", "pROC", "ellipse", 
                  "scatterplot3d", "siggenes", "globaltest", 
                  "GlobalAncova", "Rgraphviz", "KEGGgraph", 
                  "SSPA", "sva", "car", "fitdistrplus", 
                  "R.utils", "metabomxtr", "rvest",
                  "GO.db", "WGCNA", "SDAMS", "devtools", 
                  "ROCS", "rJava", "plotly", "ptw", 
                  "tcltk2", "pca3d", "imager", 
                  character.only = TRUE)

#install.necessary.packages <- function(pkg){
#    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
#    if (length(new.pkg)) install.packages(new.pkg)
#}

#install.necessary.packages(necessary_packages)

if(!require(MetaboAnalystR)){devtools::install_github("xia-lab/MetaboAnalystR", 
                                                      build_vignettes = TRUE)}
#vignette(package="MetaboAnalystR")

update.packages()
source("https://bioconductor.org/biocLite.R")
biocLite()
tryCatch({biocLite("BiocUpgrade")}, error=function(e){print(paste(conditionMessage(e)))})
biocValid()

devtools::install_git("https://gitlab.com/R_packages/massageR.git")
devtools::install_github("stanstrup/QC4Metabolomics/MetabolomiQCsR")
devtools::install_github("stanstrup/commonMZ")

library(MSnbase)
library(xcms)
library(CAMERA)
library(IPO)
library(MetaboAnalystR)
library(MetabolomiQCsR)

library(doParallel)
library(RColorBrewer)

library(plotly)
library(rJava)
```

```{r Convert Agilent data to mzML}
'msconvert *.d -o mzML'
```

```{r Load data, include=FALSE}
path.pos <- "data/Rik/ESI+" #### path to converted positive mzML files
path.neg <- "data/Rik/ESI-"

### Creating sub-directories for samples/batches are allowed and recommended
pos.mzml <- list.files(path.pos, recursive = T, full.names = T, pattern=".mzML")
pos.mzml

neg.mzml <- list.files(path.neg, recursive = T, full.names = T, pattern=".mzML")
neg.mzml
```

**PEAK PICKING METHOD**  
- 'matchedfilter' is used by default (when 'xcmsSet' method is used for loading data)  
- 'centWave' is commonly used for high resolution spectra/MS data  
- Irregardless of the peak picking method chosen, there are many parameters that can be tuned. The rule of thumb is, if you do not understand what a parameter exactly does, then it is best to use the default value.  
- "Mass deviation μ in ppm, typically set to a generous multiple of the mass accuracy of the mass spectrometer. We use μ = 30 ppm for the Bruker MicrOTOF-Q, which is advertised with a mass accuracy of 3–5 ppm". (doi: 10.1186/1471-2105-9-504)  
- Q: How do we find the best tuning parameters for our dataset? (e.g. 'fwhm' specifies full width at half maximum (default is 30s) based on the type of chromatography)  
- Q: Is it a good idea to load all sample sets (Fresh, Frozen 24h, Frozen 1w) into one xcmsSet?

```{r xcmsSet / peak identification}
param.ppm <- 30
param.snthresh <- 65
param.prefilter <- c(5, 10000)
param.noise <- 6500
param.peakwidth <- c(12,28)
param.parallelization <- MulticoreParam(floor(detectCores() * 0.9)) ### use 90% of the cores for parallel computing

xset.pos.centw <- xcmsSet(pos.mzml, method = "centWaveWithPredictedIsotopeROIs", 
                          ppm = param.ppm, 
                          snthresh = param.snthresh, 
                          prefilter = param.prefilter, 
                          noise = param.noise, 
                          peakwidth = param.peakwidth,
                          BPPARAM = param.parallelization)

xset.pos.mquant <- xcmsSet(pos.mzml, method = "massifquant", 
                           withWave = TRUE, 
                           ppm = param.ppm, 
                           snthresh = param.snthresh, 
                           prefilter = param.prefilter, 
                           noise = param.noise, 
                           peakwidth = param.peakwidth,
                           BPPARAM = param.parallelization)

param.neg.ppm <- 30
param.neg.snthresh <- 30
param.neg.prefilter <- c(5, 9000)
param.neg.noise <- 4500
param.neg.peakwidth <- c(12,35)

xset.neg.centw <- xcmsSet(neg.mzml, method = "centWaveWithPredictedIsotopeROIs", 
                          ppm = param.neg.ppm, 
                          snthresh = param.neg.snthresh, 
                          prefilter = param.neg.prefilter, 
                          noise = param.neg.noise, 
                          peakwidth = param.neg.peakwidth,
                          BPPARAM = param.parallelization)

xset.neg.mquant <- xcmsSet(neg.mzml, method = "massifquant", 
                           withWave = TRUE, 
                           ppm = param.neg.ppm, 
                           snthresh = param.neg.snthresh, 
                           prefilter = param.neg.prefilter, 
                           noise = param.neg.noise, 
                           peakwidth = param.neg.peakwidth,
                           BPPARAM = param.parallelization)
```


```{r Viewing the constructed xcmsSet, echo=FALSE}
xset.pos.centw
xset.pos.mquant
xset.neg.centw
xset.neg.mquant
```


```{r Peaks}
message(paste0("Sample groups: "))
print(levels(sampclass(xset.pos.centw)))
head(xset.pos.centw@peaks)
dim(xset.pos.centw@peaks)

message(paste0("Sample groups: "))
print(levels(sampclass(xset.pos.mquant)))
head(xset.pos.mquant@peaks)
dim(xset.pos.mquant@peaks)

message(paste0("Sample groups: "))
print(levels(sampclass(xset.neg.centw)))
head(xset.neg.centw@peaks)
dim(xset.neg.centw@peaks)

message(paste0("Sample groups: "))
print(levels(sampclass(xset.neg.mquant)))
head(xset.neg.mquant@peaks)
dim(xset.neg.mquant@peaks)
```

**mz** Intensity weighted mean of m/z values of the peak across scans.  
**mzmin** Minimum m/z of the peak.  
**mzmax** Maximum m/z of the peak.  
**rt** Retention time of the peak’s midpoint.  
**rtmin** Minimum retention time of the peak.  
**rtmax** Maximum retention time of the peak.  
**into** Integrated (original) intensity of the peak.  
**intf** Integrated intensity of the filtered peak.  
**maxo** Maximum intensity of the peak.  
**maxf** Maximum intensity of the filtered peak.  
**i** Rank of peak in merged EIC (<= max).  
**sn** Signal to noise ratio of the peak  

- Grouping has its own methods too (density, mzClust, nearest)  
Q: How do we tune grouping parameters? How do we find the best ones for our data?  
```{r Grouping peaks representing the same analyte across samples / matching peaks across samples}
#?group.density
#?group.mzClust
#?group.nearest

#xsg.pos <- group(xset.pos, sleep = 0.02)

xsg.pos.centw <- group(xset.pos.centw)
xsg.pos.mquant <- group(xset.pos.mquant)

xsg.neg.centw <- group(xset.neg.centw)
xsg.neg.mquant <- group(xset.neg.mquant)

xsg.pos.centw.mzClust <- group.mzClust(xset.pos.centw, mzppm = 5)
xsg.pos.mquant.mzClust <- group.mzClust(xset.pos.mquant, mzppm = 5)

xsg.neg.centw.mzClust <- group.mzClust(xset.neg.centw, mzppm = 5)
xsg.neg.mquant.mzClust <- group.mzClust(xset.neg.mquant, mzppm = 5)
```


There are a few retention time correction methods in xcms: Gaussian, Symmetric, and Obiwarp.  
Plot shows the data points used for regression and the resulting deviation profiles. It can be used for supervising the algorithm. The distribution of peak groups across retention time is also shown in the plot.  
```{r Retention time correction}
xsg.pos.centw.retcor <- retcor(xsg.pos.centw, family="gaussian", plottype="mdevden")
xsg.pos.mquant.retcor <- retcor(xsg.pos.mquant, family="gaussian", plottype="mdevden")

xsg.neg.centw.retcor <- retcor(xsg.neg.centw, family="gaussian", plottype="mdevden")
xsg.neg.mquant.retcor <- retcor(xsg.neg.mquant, family="gaussian", plottype="mdevden")

xsg.pos.centw.mzClust.retcor <- retcor(xsg.pos.centw.mzClust, family="gaussian", plottype="mdevden")
xsg.pos.mquant.mzClust.retcor <- retcor(xsg.pos.mquant.mzClust, family="gaussian", plottype="mdevden")

xsg.neg.centw.mzClust.retcor <- retcor(xsg.neg.centw.mzClust, family="gaussian", plottype="mdevden")
xsg.neg.mquant.mzClust.retcor <- retcor(xsg.neg.mquant.mzClust, family="gaussian", plottype="mdevden")

#xsg.pos.retcor.symmetric <- retcor(xsg.pos, family="symmetric", plottype="mdevden")
#xsg.pos.retcor.obiwarp <- retcor.obiwarp(xsg.pos, plottype="deviation")

xsg.pos.centw.retcor.obiwarp <- retcor.obiwarp(xsg.pos.centw, plottype="deviation")
xsg.pos.mquant.retcor.obiwarp <- retcor.obiwarp(xsg.pos.mquant, plottype="deviation")

xsg.neg.centw.retcor.obiwarp <- retcor.obiwarp(xsg.neg.centw, plottype="deviation")
xsg.neg.mquant.retcor.obiwarp <- retcor.obiwarp(xsg.neg.mquant, plottype="deviation")

xsg.pos.centw.mzClust.retcor.obiwarp <- retcor.obiwarp(xsg.pos.centw.mzClust, plottype="deviation")
xsg.pos.mquant.mzClust.retcor.obiwarp <- retcor.obiwarp(xsg.pos.mquant.mzClust, plottype="deviation")

xsg.neg.centw.mzClust.retcor.obiwarp <- retcor.obiwarp(xsg.neg.centw.mzClust, plottype="deviation")
xsg.neg.mquant.mzClust.retcor.obiwarp <- retcor.obiwarp(xsg.neg.mquant.mzClust, plottype="deviation")
```


When re-grouping the retention time-corrected xset, parameters can also be re-tuned once more. For example, we can choose a narrower 'bw'.  
```{r Re-grouping peaks representing the same analyte across samples. Grouping/retention time correction can and must be repeated several times}
xsg.gaus.pos <- group(xsg.pos.mquant.mzClust.retcor.obiwarp)
xsg.gaus.pos <- retcor.obiwarp(xsg.gaus.pos, plottype="deviation")
xsg.gaus.pos <- group(xsg.gaus.pos)

xsg.gaus.neg <- group(xsg.neg.mquant.mzClust.retcor.obiwarp)
xsg.gaus.neg <- retcor(xsg.gaus.neg, family="gaussian", plottype="mdevden")
xsg.gaus.neg <- group(xsg.gaus.neg)

#xsg.sym <- group(xsg.pos.retcor.symmetric, bw=10)
#xsg.obw <- group(xsg.pos.retcor.obiwarp, bw=10)
```


```{r Fill in missing peaks using original data, message=FALSE, warning=FALSE}
xsg.gaus.pos <- fillPeaks(xsg.gaus.pos)
xsg.gaus.neg <- fillPeaks(xsg.gaus.neg)
#xsg.sym <- fillPeaks(xsg.sym)
#xsg.obw <- fillPeaks(xsg.obw)
```

```{r QC}

###intensity
boxplot(groupval(xsg.gaus.pos, value="into")+1, 
        col=as.numeric(sampclass(xsg.gaus.pos))+1, 
        log="y", las=2)

plotQC(xsg.gaus.pos)

sdThresh <- 4.0 ## Filter low-standard deviation rows for plot
data <- log(groupval(xsg.gaus.pos, value="into")+1)

pca.result <- pcaMethods::pca(data, nPcs = 8)
pcaMethods::plotPcs(pca.result, type="loadings", 
        col=as.numeric(sampclass(xsg.gaus.pos))+1)

pcares <- as.data.frame(pca.result@loadings)

plotly::plot_ly(pcares, x = ~PC1, y = ~PC2, z = ~PC3, color = (sampclass(xsg.gaus.pos)), colors = c("#377EB8", "#4DAF4A")) %>%
    add_markers() %>%
    layout(scene = list(xaxis = list(title = 'PC #1'),
                        yaxis = list(title = 'PC #2'),
                        zaxis = list(title = 'PC #3')))

#pca <- prcomp(t(data), scale.=TRUE)
#gr <- factor(as.numeric(sampclass(xsg.gaus))+1)
#summary(gr)
#pca3d(pca, group=gr)
```

```{r Internal standard}
mzml.file <- xcmsRaw("~/pbio/LC-MS/Data/QTOF_IMPC/FreezingExperiment/ESI+/14_days/83S-A0955_m_WT_FreezinExperiment2_14days_ESI+.mzML")
mzr = c(288.2, 292.227)
rtr = c(10.234*60, 10.402*60)
plotRaw(mzml.file, mzrange = mzr, rtrange = rtr)

all.mzml <- extractMsData(readMSData(list.files(path = "~/pbio/LC-MS/Data/QTOF_IMPC/FreezingExperiment/ESI+/28_days/", full.names = T), mode = "onDisk"), mz = mzr, rtr)
for(i in 1:length(all.mzml)){
    ggsave(filename = paste0("internal_standard",i,".png"), 
           plot = plotMsData(all.mzml[[i]]), 
           device = "png", dpi = 600, 
           width = 10, height = 10)
    graphics.off()
}
```

"into" and "maxo" are (or at least seem to be) peak intensities and areas, respectively.  
Peak list:  
```{r Results of peak detection}
peaks(xsg.gaus.pos)[1:25,]
dim(xsg.gaus.pos@peaks)
#dim(peaks(xsg.gaus.pos)) ### Another way of doing what was done in the previous line

peaks(xsg.gaus.neg)[1:25,]
dim(xsg.gaus.neg@peaks)
```

‘diffreport’ computes Welch's two-sample t-statistic for each analyte and ranks them by p-value. In brief, it performs univariate analysis on our peaks.  
Q: When using 'diffreport', it is possible to include three sample classes (or even many more) by defining the class1/class2 arguments as c("sample2","sample3"). Does that, however, have any impact on the final result? In brief, is there a difference between `class1=c("Mouse1", "Mouse2"), class2="Mouse5"` and `class1="Mouse1", class2=c("Mouse2","Mouse5")`  
```{r Extracting ion chromatograms for significant ions and reporting the most statistically significant differences in analyte intensities / A report showing the most significant differences between two sets of samples, message=FALSE}
rep.gaus.pos <- diffreport(object = xsg.gaus.pos, 
                       class1 = levels(sampclass(xsg.gaus.pos))[1], 
                       class2 = levels(sampclass(xsg.gaus.pos))[2], 
                       filebase = "diffreport_ESI_pos", eicmax = 40, 
                       sortpval = TRUE,
                       metlin = 0.5, mzdec = 5)

rep.gaus.neg <- diffreport(object = xsg.gaus.neg, 
                       class1 = levels(sampclass(xsg.gaus.neg))[1], 
                       class2 = levels(sampclass(xsg.gaus.neg))[2], 
                       filebase = "diffreport_ESI_neg", eicmax = 40, 
                       sortpval = TRUE,
                       metlin = 0.5, mzdec = 5)

#### quality of peaks can be inspected by checking the figures in report_eic folder

#rep.sym <- diffreport(xsg.sym, "Fresh", c("Frozen 1w", "Frozen 24h"), "Symmetric", 10, metlin=0.15)
#rep.obw <- diffreport(xsg.obw, "Fresh", c("Frozen 1w", "Frozen 24h"), "Obiwarp", 10, metlin=0.15)

rep.gaus.pos[1:25,]
tail(rep.gaus.pos)

rep.gaus.neg[1:25,]
tail(rep.gaus.neg)

#rep.sym[1:10,]
#rep.obw[1:10,]
```

```{r DifferentPeaks}
eic <- list.files("diffreport_eic", full.names = T, recursive = T)
im <- list()
for(i in 1:length(eic)) {
  im[[i]] <- load.image(eic[i])
  plot(im[[i]])
  }
```


```{r Constructing peak intensity matrix for multivariate analysis using MetaboAnalyst.ca}
#– Features (peaks) are in rows
#– Samples are in  columns
#– Group labels must be added by using 'phenoData'
#- If there are duplicated mzRT values in the rows of the generated peak intensity matrix, MetaboAnalyst will result in an error. To fix this error, simply distinguish repeated values by adding 'A', 'B', 'C', etc. to them. For example, if you have the mzRT feature 54.04/1499.3 twice in the resulting table, simply change the second one to 54.04/1499.3A
dat <- groupval(xsg.gaus.pos, "medret", "into")
rownames(dat) <- groupnames(xsg.gaus.pos, mzdec=5, rtdec=5)
dat <- rbind(group = as.character(phenoData(xsg.gaus.pos)$class), dat)
write.csv(dat, file='ESI+_PeakIntensityMatrix_MetaboAnalyst.csv')
head(dat)
tail(dat)
#rm(dat)

datneg <- groupval(xsg.gaus.neg, "medret", "into")
rownames(datneg) <- groupnames(xsg.gaus.neg, mzdec=5, rtdec=5)
datneg <- rbind(group = as.character(phenoData(xsg.gaus.neg)$class), datneg)
write.csv(datneg, file='ESI-_PeakIntensityMatrix_MetaboAnalyst.csv')
head(datneg)
tail(datneg)
#rm(datneg)

#dat <- groupval(xsg.sym, "medret", "into")
#dat <- rbind(group = as.character(phenoData(xsg.sym)$class), dat)
#write.csv(dat, file='Symmetric_PeakIntensityMatrix.csv')
#rm(dat)

#dat <- groupval(xsg.obw, "medret", "into")
#dat <- rbind(group = as.character(phenoData(xsg.obw)$class), dat)
#write.csv(dat, file='Obiwarp_PeakIntensityMatrix.csv')
#rm(dat)
```

```{r Extracted ion chromatogram (EIC) / Assessing the quality of detected peaks}
#gt.gaus <- groups(xsg.gaus)
#gt.gaus[1:3,]

#gt.sym <- groups(xsg.sym)
#gt.sym[1:3,]

#gt.obw <- groups(xsg.obw)
#gt.obw[1:3,]

#grp_idx_gaus <- which(gt.gaus[,"rtmed"] > 0 & gt.gaus[,"rtmed"] < 500 & gt.gaus[,"npeaks"] > 50)[1]
#eiccor.gaus <- getEIC(xsg.gaus, groupidx=grp_idx_gaus)
#plot(eiccor.gaus, col=as.numeric(phenoData(xsg.gaus)$class))
```

```{r Independent Component Analysis (ICA) / T-distributed Stochastic Neighbor Embedding (tSNE) --- UNDER DEVELOPMENT | Be cautious}
t <- dat
head(t)
labels.plot <- t[1,][-1]
t <- t[-1,]

# for(i in 1:dim(t)[2]){
# t[,i] <- as.numeric(as.character(t[,i]))
# }

write.csv(x = t, file = "t.csv")
t <- (read.csv("t.csv", header = TRUE, stringsAsFactors = FALSE, row.names = 1, check.names = FALSE))

tICA <- fastICA::fastICA(t, n.comp = 2)

sample_colors <- brewer.pal(2, "Set1")[1:2]
names(sample_colors) <- unique(labels.plot)
cols <- paste0(sample_colors[labels.plot], 80)
tTSNE.features <- Rtsne(t)
tTSNE.samples <- Rtsne(t(t), perplexity = 4)
#par(mfrow=c(3,1))
plot(tICA$S, col=cols, cex=2, pch=16, main="Independent Component Analysis (ICA)\nSamples")
plot(tTSNE.features$Y, main = "T-distributed Stochastic Neighbor Embedding (tSNE)\nFeatures")
plot(tTSNE.samples$Y, main="T-distributed Stochastic Neighbor Embedding (tSNE)\nSamples", col=cols, pch=16, cex=3)

# MetaboDiff::tsne_plot()
# https://towardsdatascience.com/use-of-t-sne-to-reduce-the-dimensionality-of-metabolomics-datasets-f8a36120ca32
# https://distill.pub/2016/misread-tsne/#citation
# https://medium.com/@danielcanueto/validation-of-the-benefits-of-use-of-t-sne-in-metabolomics-studies-5018253b8173
# https://medium.com/@TheDataGyan/dimensionality-reduction-with-pca-and-t-sne-in-r-2715683819
```


```{r Metabolite Identification using MassBank of North America}
significant_features_mz <- c(902.433, 532.044, 122.456) ### this list comes from prior statistical analysis
identified <- list(NULL)
ionization_mode <- "positive"
mz_tolerance <- 0.5

for(i in 1:length(significant_features_mz)){
  lower_bound <- significant_features_mz[i] - mz_tolerance
  upper_bound <- significant_features_mz[i] + mz_tolerance
  identified[[i]] <- jsonlite::fromJSON(paste0("http://mona.fiehnlab.ucdavis.edu/rest/spectra/search?page=0&query=compound.metaData%3Dq%3D%27name%3D%3D%22total+exact+mass%22+and+value+%3E%3D+", lower_bound, "+and+value+%3C%3D+", upper_bound,
"%27+and+(tags.text%3D%3D%22LC-MS%22)+and+(metaData%3Dq%3D%27name%3D%3D%22ionization+mode%22+and+value%3D%3D%22positive%22%27)+and+(metaData%3Dq%3D%27name%3D%3D%22ms+level%22+and+value%3D%3D%22MS1%22%27)&size=30&text="))
  Sys.sleep(time = 5) ### introduce a small pause between searches to avoid IP ban
}

identified[[1]]$metaData[[1]]$value
identified[[1]]$compound[[1]]$inchi
identified[[1]]$compound[[1]]$names
lapply(identified[[1]]$compound, `[`, 4) ### name of all hits for the first m/z value
identified[[1]]$compound[[1]]$classification
identified[[1]]$compound[[1]]$metaData[[1]]

#decoded.url <- jsonlite::fromJSON("http://mona.fiehnlab.ucdavis.edu/rest/spectra/search?page=0&query=compound.metaData=q='name=="total exact mass" and value >= 245 and value <= 255' and (tags.text=="LC-MS") and (metaData=q='name=="ionization mode" and value=="positive"') and (metaData=q='name=="ms level" and value=="MS1"')&size=30&text=")

#utils::URLdecode()
```


```{r Metabolite identification using Metlin}
significant_features_mz <- c(418.2931, 540.29)
mz_tolerance_ppm <- 5

### Charge is ESI+
### Adduct: M+H

metlin_table <- list(NULL)
metlin_res <- list(NULL)
metlin_res_tbl <- list(NULL)

for(i in length(significant_features_mz)){
  metlin_table[[i]] <- xml2::read_html(paste0('https://metlin.scripps.edu/simple_search_result.php?mass_mid=', significant_features_mz[i],
       '&mass_tol=', mz_tolerance_ppm, '&mass_mode=1&AminoAcid=add&toxinEPA=add&adducts=M%2BH'))
  metlin_res[[i]] <- rvest::html_nodes(metlin_table[[i]], "table")
  metlin_res_tbl[[i]] <- rvest::html_table(metlin_res[[i]][1], fill = TRUE)
  print(head(metlin_res_tbl[[i]][[1]]))
}
```


```{r Metabolite identification using multiple databases}
databases <- c("pubchem", "hmdb", "lipidmaps",
               "flavonoidviewer", "knapsack",
               "kegg", "pep1000", "exmassdb")

mz_tolerance = 0.5
target_masses = c(102.3201, 452.02)
hits <- list(NULL)

for(i in 1:length(target_masses)){
  searches <- paste0("http://webs2.kazusa.or.jp/mfsearcher/", databases, "/mass?targetMs=", target_masses[i], "&margin=", mz_tolerance)
  search_for_hits <- lapply(searches, FUN = read.csv, sep = "\t", header = FALSE,
                            col.names = c("Database", "Molecular.Formula", "DBE", "Formula.Weight", "ID.in.DB", "Description"))
  hits_merged <- Reduce(function(x, y) rbind(x, y), search_for_hits)
  hits[[i]] <- hits_merged
  rm(hits_merged)
}
```


Processing with peakML  
```{r PeakML}
source ("http://puma.ibls.gla.ac.uk/mzmatch.R/install_mzmatch.R")
.jinit ()
mzmatch.init()
PeakML.xcms.write(xsg.gaus.neg, "xsg_gaus_neg.peakml")
mzmatch.init(version.1 = FALSE)
mzmatch.ipeak.sort.MetAssign(JHeapSize = 180000, i = "xsg_gaus_neg.peakml", o = "xcms_identified.peakml", 
                             basepeaks = "xcms_basepeaks.peakml", ppm = 3, numDraws = 300, burnIn = 200, 
                             adducts = "M+H,M+NH4", 
                             dbIdentOut = "xcms_neg_Probabilistic_metabolite_annotation.csv", v = TRUE)

### PeakML.Viewer() ### Load generated peakML files
```

```{r apLCMS pipeline}
#####This section is currently under construction (apLCMS might not be as reliable as xcms)
#apLCMS.set <- apLCMS::cdf.to.ftr(path.pos, file.pattern = ".mzXML")
```

```{r IPO / XCMS Parameter Optimization, eval=FALSE}
peakpickingParameters <- IPO::getDefaultXcmsSetStartingParams('centWave')
peakpickingParameters$min_peakwidth <- c(12,35)
peakpickingParameters$max_peakwidth <- c(15, 65)
peakpickingParameters$ppm <- c(10,40)
peakpickingParameters$snthresh <- c(10,80)
peakpickingParameters$noise <- 5000
peakpickingParameters$prefilter <- c(3,5)
peakpickingParameters$value_of_prefilter <- c(3000,15000)
peakpickingParameters$fitgauss <- TRUE
peakpickingParameters$nSlaves <- 11

data <- list.files("data/Rik/ESI+/", recursive = T, full.names = T, pattern = ".mzML")

optimized.xcmsSet <- system.time({
    resultPeakpicking <- optimizeXcmsSet(files = data, 
                                         params = peakpickingParameters,
                                         subdir = "IPO_plots", nSlaves = 12)
})

```

```{r XCMS3 Pipeline}
register(bpstart(MulticoreParam(150)))
files.path <- "~/PRIMUS/data/83_BIOINFORMATICS/Ashkan/LC-MS/Data/QTOF_IMPC/Rik/ESI+"
mzml.files <- list.files(files.path, recursive = T, full.names = T, pattern=".mzML")
mzml.files

pheno_data <- data.frame(sample_name = sub(basename(mzml.files), pattern = ".mzML", replacement = "", fixed = TRUE),
                         sample_group = c(rep("Rik", 14), rep("WT", 14)),
                         stringsAsFactors = FALSE)

raw_data <- readMSData(files = mzml.files, pdata = new("NAnnotatedDataFrame", pheno_data), mode = "onDisk") ###MSnbase can convert 'profile' to 'centroid'. More information: browseVignettes("MSnbase")

spectra(raw_data)
head(rtime(raw_data), n = 25)

mzs <- mz(raw_data)
mzs_by_file <- split(mzs, f = fromFile(raw_data)) ## split the list by file / organize mz values by file
length(mzs_by_file)

rts <- rtime(raw_data)
rts_by_file <- split(rts, f = fromFile(raw_data)) ## split the list by file / organize mz values by file
length(rts_by_file)
lapply(rts_by_file, range)
lapply(rts_by_file, range) %>% lapply(`[`, 2) %>% unlist %>% sort

## BPC

bpis <- chromatogram(raw_data, aggregationFun = "max") ## Get the base peak chromatograms. This reads data from the files.
tic <- chromatogram(raw_data, aggregationFun = "sum") ## TIC (Total Ion Current)
sample_groups <- unique(pheno_data$sample_group)
group_colors <- brewer.pal(9, "Set1")[1:length(sample_groups)] ## Define colors for the groups in the data
names(group_colors) <- sample_groups

dir.create("QC")
png("QC/01 - BPC.png", width = 7, height = 7, units = "in", res = 1200)
plot(bpis, col = group_colors[raw_data$sample_group], main = "Base Peak Chromatogram (BPC)")
legend("topleft", col = group_colors, legend = names(group_colors), lty = 1)
dev.off()

png("QC/02 - TIC.png", width = 7, height = 7, units = "in", res = 1200)
plot(tic, col = group_colors[raw_data$sample_group], main = "Total Ion Current (TIC)")
legend("topleft", col = group_colors, legend = names(group_colors), lty = 1)
dev.off()



bpi_1 <- bpis[1, 1] ### chromatogram of the first sample
head(rtime(bpi_1))
head(intensity(bpi_1))


tc <- split(tic(raw_data), f = fromFile(raw_data)) ### helpful in detecting problematic or failing MS runs
png("QC/03 - TIC_distribution_per_file.png", width = 7, height = 7, units = "in", res = 600)
boxplot(tc, col = group_colors[raw_data$sample_group],
        ylab = "Intensity", main = "Distribution of total ion currents per file")
dev.off()

## Visually inspect the EIC of internal controls, known compounds/peaks, etc. to evaluate and adapt the peak detection settings
## Peak widths can be inspected in this way as well, and in turn help us to choose
## better peak widths for centWave or other algorithms.
## such checks are necessary for choosing the correct `peakwidth` (expected range of **chromatographic** peak widths) and ppm (maximum expected deviation of m/z values of centroids corresponding to one chromatographic peak; this is usually much larger than the ppm specified by the manufacturer) parameters
## Use ToppView or mzMine to do the same as well.


## Define the rt and m/z range of the peak area
#rtr <- c(520, 540) ### Testosterone 13C (C16[13C]3H28O2) is at 8.8 min
#mzr <- c(292.13, 292.26) ### Mass of Testosterone 13C (C16[13C]3H28O2) is 292.21899

### in many datasets Testosterone 13C was found in the following range:
mzr <- c(291.1434,291.1444)
rtr <- c(635,695)

## extract the chromatogram and inspect the peakwidth and set the peak picking parameter accordingly
chr_raw <- chromatogram(raw_data, mz = mzr, rt = rtr)
png(paste0("QC/04 - EIC. ", "mz_", mzr[1], "-", mzr[2], "_-_RT_", rtr[1], "-", rtr[2], ".png"),
    width = 7, height = 7, units = "in", res = 600)
plot(chr_raw, col = group_colors[chr_raw$sample_group], 
     main = paste0("EIC. m/z: ", mzr[1], "-", mzr[2], " | RT: ", rtr[1], "-", rtr[2]))
legend("topleft", col = group_colors, legend = names(group_colors), lty = 1)
dev.off()

#Note that Chromatogram objects extracted by the chromatogram method contain an NA value if in a certain scan (i.e. for a specific retention time) no signal was measured in the respective mz range. This is reflected by the lines not being drawn as continuous lines in the plot above.

# # # # # # #
# A small shiny application to interactively plot EICs

shiny_EIC <- function(){
  shinyApp(
  ui = fluidPage(
    titlePanel("EIC"),
    
    sidebarLayout(
      sidebarPanel(
        
        fluidRow(
          column(3, 
          shiny::numericInput(inputId = "mz_min", label = "m/z min", value = 225.12),
          shiny::numericInput(inputId = "mz_max", label = "m/z max", value = 225.5)
          ),

          column(3, 
          shiny::numericInput(inputId = "rt_min", label = "RT min", value = 200),
          shiny::numericInput(inputId = "rt_max", label = "RT max", value = 210)
          )
        ),
        
        submitButton("Update View", icon("refresh"))
      ),
      
      mainPanel(width = 12,
        plotOutput(outputId = "EICplot", height = 850)
        
      )
    )
  ), 
  
  server = function(input, output) {
    output$EICplot <- renderPlot({
      
      chr_raw <- xcms::chromatogram(raw_data, mz = c(input$mz_min, input$mz_max), rt = c(input$rt_min, input$rt_max))
      plot(chr_raw, col = group_colors[chr_raw$sample_group], 
           main = paste0("EIC. m/z: ", input$mz_min, "-", input$mz_max, 
                         " | RT: ", input$rt_min, "-", input$rt_max))
      legend("topleft", col = group_colors, legend = names(group_colors), lty = 1)
      
    })
    
  }
)
}



# # # # # # #

## For the ppm parameter we extract the full MS data (intensity, retention time and m/z values) corresponding to the above peak.
## To this end we first filter the raw object by retention time, then by m/z and finally plot the object with type = "XIC" to produce the plot below.
## the ppm parameter is usually set to a much higher value than advertised by the vendor of the machine
png("QC/05 - mz_shift_per_file.png", width = 7, height = 7, units = "in", res = 600)
raw_data %>%
    filterRt(rt = rtr) %>%
    filterMz(mz = mzr) %>%
    plot(type = "XIC")
dev.off()

cl <- parallel::makeCluster(100)
doParallel::registerDoParallel(cl)

raw_data_filtered <- raw_data %>% filterRt(rt = rtr) %>% filterMz(mz = mzr)
dir.create("QC/05 - mz_shift_per_file/")
foreach::foreach(i = 1:(dim(raw_data@phenoData@data)[1]), 
                 .packages = c('dplyr', 'xcms')) %dopar% {
  png(paste0("QC/05 - mz_shift_per_file/05 - mz_shift_in_file_", i, ".png"), 
      width = 7, height = 7, units = "in", res = 1200)
  raw_data_filtered %>% filterFile(i) %>% plot(type = "XIC")
dev.off()
}

parallel::stopCluster(cl)

## Inspect the lower panel
## If you see a straight line, this means there is no variation in the m/z values for that particular peak
## Usually one would see the m/z values (lower panel) scatter around the real m/z value of the compound. It is suggested to inspect the ranges of m/z values for many compounds (either internal standards or compounds known to be present in the sample) and define the ppm parameter for centWave according to these.

# noise = 12000 means only signals with a value larger than 12000 are considered in peak peaking

cwp <- CentWaveParam(peakwidth = c(8, 25), noise = 2000, ppm = 30, 
                     snthresh = 9, prefilter = c(5,3000), fitgauss = TRUE)
xdata <- findChromPeaks(raw_data, param = cwp)

peaklist <- chromPeaks(xdata)
peaklist %>% head

write.csv(x = peaklist, file = "QC/Peaklist.csv")

#The returned matrix provides the m/z and retention time range for each identified chromatographic peak as well as the integrated signal intensity (“into”) and the maximal peak intensitity (“maxo”). Column “sample” contains the index of the sample in the object/experiment in which the peak was identified.


### per file (sample) statistics
peakTab <- lapply(split.data.frame(chromPeaks(xdata),
                 f = chromPeaks(xdata)[, "sample"]),
        FUN = function(z) {
    c(peak_count = nrow(z), rt = quantile(z[, "rtmax"] - z[, "rtmin"]))
})
peakTab <- do.call(rbind, peakTab)
rownames(peakTab) <- basename(fileNames(xdata))
pander::pandoc.table(peakTab,
         caption = paste0("Summary statistics on identified chromatographic",
                  " peaks. Shown are number of identified peaks per",
                  " sample and widths/duration of chromatographic ",
                  "peaks."))
print(peakTab)
table(chromPeaks(xdata)[, "sample"])
write.csv(x = peakTab, file = "QC/Identified_peaks_summary.csv")

### plot the location of the identified chromatographic peaks in the m/z - retention time space for each file
dir.create("QC/06 - location_of_identified_peaks/")

cl <- parallel::makeCluster(100)
doParallel::registerDoParallel(cl)

foreach::foreach(i = 1:(dim(raw_data@phenoData@data)[1])) %dopar% {
    png(paste0("QC/06 - location_of_identified_peaks/06 - location_of_identified_peaks_in_file_", i, ".png"), 
        width = 7, height = 7, units = "in", res = 1200)
    xcms::plotChromPeaks(xdata, file = i)
    dev.off()
}

parallel::stopCluster(cl)

### plot the frequency of identified peaks per file along the retention time axis. This allows to identify time periods along the MS run in which a higher number of peaks was identified and evaluate whether this is consistent across files.
### The frequency is color coded with higher frequency being represented by yellow-white.
png("QC/07 - Peak_frequency.png", width = 10, height = 7, units = "in", res = 1200)
plotChromPeakImage(xdata, main = "Frequency of identified chromatographic peaks along the retention time axis")
dev.off()



### Plot the density of chromatographic peaks along the retention time axis and indicate which peaks would be (or were) grouped into the same feature based using the peak density correspondence method.
png("QC/08 - Peak_Density.png", 
    width = 15, height = 7, units = "in", res = 1200)
plotChromPeakDensity(xdata)
dev.off()

png("QC/08 - Peak_Density_specific_mz_rt_window.png", 
    width = 15, height = 7, units = "in", res = 1200)
plotChromPeakDensity(xdata, mz = mzr, rt = rtr)
dev.off()

## Highlight identified peaks
## Evaluating such plots on a list of peaks corresponding to known peaks or internal standards helps to ensure that peak detection settings were appropriate and correctly identified the expected peaks.

chr_raw <- chromatogram(raw_data, mz = mzr, rt = rtr)
png(paste0("QC/09 - Identified_peaks_in_mz_", mzr[1], "-", mzr[2], 
           "_rt_", rtr[1], "-", rtr[2], ".png"), width = 15, height = 7, unit = "in",
    res = 1200)
plot(chr_raw, col = group_colors[chr_raw$sample_group], lwd = 2)
highlightChromPeaks(xdata, border = group_colors[chr_raw$sample_group],
                    lty = 3, rt = rtr, mz = mzr)
dev.off()

## Take a look at some of the identified peaks
random_peak_idx <- c(1, 5, 10, 50, 100, sample(seq(from = 1, to = dim(chromPeaks(xdata))[1], by = 3), size = 100, replace = TRUE))

cl <- parallel::makeCluster(50)
doParallel::registerDoParallel(cl)
dir.create("QC/09 - EIC")

foreach::foreach(i = random_peak_idx, .packages = c('dplyr', 'xcms')) %dopar% {
    
    mzr <- c(chromPeaks(xdata)[i,"mzmin"], chromPeaks(xdata)[i,"mzmax"])
    rtr <- c(chromPeaks(xdata)[i,"rtmin"] %>% floor, chromPeaks(xdata)[i,"rtmax"] %>% ceiling)
    
    chr_raw <- chromatogram(raw_data, mz = mzr, rt = rtr)
    
    png(paste0("QC/09 - EIC/09 - Identified_peaks_in_mz_", mzr[1], "-", mzr[2], "_rt_", rtr[1], "-", rtr[2], ".png"), 
        width = 15, height = 7, unit = "in", res = 400)
    
    plot(chr_raw, col = group_colors[chr_raw$sample_group], lwd = 2)
    highlightChromPeaks(xdata, border = group_colors[chr_raw$sample_group], lty = 3, rt = rtr, mz = mzr)
    
    dev.off()
}

parallel::stopCluster(cl)

## Extract identified chromatographic peaks in a region
pander::pander(chromPeaks(xdata, mz = mzr, rt = rtr),
       caption = paste("Identified chromatographic peaks in a selected ",
               "m/z and retention time range."))


### distribution of peak intensity per sample
### This allows to investigate whether systematic differences in peak signals between samples are present.
## Extract a list of per-sample peak intensities (in log2 scale)
png("QC/10 - distribution_of_peak_intensity_per_sample.png", 
    width = 15, height = 7, units = "in", res = 1200)
ints <- split(log2(chromPeaks(xdata)[, "into"]),
          f = chromPeaks(xdata)[, "sample"])
boxplot(ints, varwidth = TRUE, col = group_colors[xdata$sample_group],
    ylab = expression(log[2]~intensity), main = "Peak intensities")
grid(nx = NA, ny = NULL)
dev.off()


# The time at which analytes elute in the chromatography can vary between samples (and even compounds). Such a difference can be inspected using the extracted ion chromatogram plots. The alignment step, also referred to as retention time correction, aims at adjusting this by shifting signals along the retention time axis to align the signals between different samples within an experiment.

# adjustRtime, besides calculating adjusted retention times for each spectrum, does also adjust the reported retention times of the identified chromatographic peaks.

# Also here it is advisable to modify the settings for each experiment and evaluate if retention time correction did align internal controls or known compounds properly.


xdata <- adjustRtime(xdata, param = ObiwarpParam(binSize = 0.6))
head(adjustedRtime(xdata))
head(rtime(xdata))  ### defaults to adjustedRtime if it's present
head(rtime(xdata, adjusted = FALSE)) ### returns original retention times

### investigate the impact of alignment by plotting BPC of the adjusted data
#To evaluate the impact of the alignment we plot the BPC on the adjusted data. In addition we plot the differences of the adjusted- to the raw retention times per sample using the  plotAdjustedRtime function.
#Too large differences between adjusted and raw retention times could indicate poorly performing samples or alignment.

## Get the base peak chromatograms.
bpis_adj <- chromatogram(xdata, aggregationFun = "max")
par(mfrow = c(2, 1), mar = c(4.5, 4.2, 1, 0.5))
png("QC/11 - obiwarp_rtime_correction.png", 
    width = 15, height = 7, units = "in", res = 1200)
plot(bpis_adj, col = group_colors[bpis_adj$sample_group])

## Plot also the difference of adjusted to raw retention time.
plotAdjustedRtime(xdata, col = group_colors[xdata$sample_group]) 
dev.off()

#use the peak groups alignment method that adjusts the retention time by aligning previously identified hook peaks (chromatographic peaks present in most/all samples). Ideally, these hook peaks should span most part of the retention time range. 
hasAdjustedRtime(xdata)
xdata <- dropAdjustedRtime(xdata)
hasAdjustedRtime(xdata)


# The definition of the sample groups (i.e. assignment of individual samples to the sample groups in the experiment) is mandatory for the PeakDensityParam. If there are no sample groups in the experiment sampleGroups should be set to a single value for each file, e.g.  rep(1, length(fileNames(xdata))).

## Correspondence: group peaks across samples.
pdp <- PeakDensityParam(sampleGroups = xdata$sample_group, 
                        bw = 6, binSize = 0.05, 
                        minFraction = 0.5, minSamples = 3)

xdata <- groupChromPeaks(xdata, param = pdp)

## Now the retention time correction.
pgp <- PeakGroupsParam(minFraction = 0.5, span = 0.55)

## Get the peak groups that would be used for alignment.
xdata <- adjustRtime(xdata, param = pgp)

# Note also that we could use the adjustRtimePeakGroups method on the object before alignment to evaluate on which features (peak groups) the alignment would be performed. This can be useful to test different settings for the peak groups algorithm. Also, it is possible to manually select or define certain peak groups (i.e. their retention times per sample) and provide this matrix to the PeakGroupsParam class with the peakGroupsMatrix argument.

# plot the difference between raw and adjusted retention times using the  plotAdjustedRtime function, which, if the peak groups method is used for alignment, also highlights the peak groups used in the adjustment.

## Plot the difference of adjusted to raw retention time.

png("QC/12 - rtime_adjusted_with_peak_grouping.png", 
    width = 15, height = 7, units = "in", res = 1200)
plotAdjustedRtime(xdata, col = group_colors[xdata$sample_group],
          peakGroupsCol = "grey", peakGroupsPch = 1)
dev.off()

# At last we evaluate the impact of the alignment on the test peak.
png("QC/13 - rtime_alignment_evaluation_on_test_peak_before_after_alignment.png", 
    width = 15, height = 7, units = "in", res = 1200)
par(mfrow = c(2, 1))
## Plot the raw data
chr_raw <- chromatogram(raw_data, mz = mzr, rt = rtr)
plot(chr_raw, col = group_colors[chr_raw$sample_group])

## Extract the chromatogram from the adjusted object
chr_adj <- chromatogram(xdata, rt = rtr, mz = mzr)
plot(chr_adj, col = group_colors[chr_raw$sample_group]) 
dev.off()

# Evaluate retention time alignment across several peaks
dir.create("QC/13 - rtime_alignment_evaluation")

cl <- parallel::makeCluster(30)
doParallel::registerDoParallel(cl)

random_peak_idx <- c(1, 5, 10, sample(seq(from = 1, to = dim(chromPeaks(xdata))[1], by = 3), size = 25, replace = TRUE))
foreach::foreach(i = random_peak_idx, .packages = c('dplyr', 'xcms')) %dopar% {
  
  mzr <- c(chromPeaks(xdata)[i,"mzmin"], chromPeaks(xdata)[i,"mzmax"])
  rtr <- c(chromPeaks(xdata)[i,"rtmin"] - 50, chromPeaks(xdata)[i,"rtmax"] + 50)
  
  png(paste0("QC/13 - rtime_alignment_evaluation/13 - rtime_alignment_mz-", 
             mzr[1], "-", mzr[2], "_rt-", rtr[1], "-", rtr[2], ".png"), 
      width = 15, height = 7, units = "in", res = 400)
  
  par(mfrow = c(2, 1))
  chr_raw <- chromatogram(raw_data, mz = mzr, rt = rtr)
  plot(chr_raw, col = group_colors[chr_raw$sample_group])
  chr_adj <- chromatogram(xdata, rt = rtr, mz = mzr)
  plot(chr_adj, col = group_colors[chr_raw$sample_group]) 
  dev.off()
}
parallel::stopCluster(cl)

### Correspondence

## Define the mz slice.
random_peak_idx <- c(1, 5, 10, sample(seq(from = 1, to = dim(chromPeaks(xdata))[1], by = 3), size = 25, replace = TRUE))

## Extract and plot the chromatograms
cl <- parallel::makeCluster(30)
doParallel::registerDoParallel(cl)

foreach::foreach(i = random_peak_idx, .packages = c('dplyr', 'xcms')) %dopar% {
  
  png(paste0("QC/14 - peak_density_correspondence", i, ".png"), width = 15, height = 13, units = "in", res = 1200)
  
  mzr <- c(chromPeaks(xdata)[i,"mzmin"], chromPeaks(xdata)[i,"mzmax"])
  rtr <- c(chromPeaks(xdata)[i,"rtmin"] %>% floor, chromPeaks(xdata)[i,"rtmax"] %>% ceiling)
  
  chr_mzr <- chromatogram(xdata, mz = mzr, rt = rtr)
  par(mfrow = c(4, 1), mar = c(1, 4, 1, 0.5))
  cols <- group_colors[chr_mzr$sample_group]
  plot(chr_mzr, col = cols, xaxt = "n", xlab = "")
  
  ## Highlight the detected peaks in that region.
  highlightChromPeaks(xdata, mz = mzr, col = cols, type = "point", pch = 16)
  
  par(mar = c(4, 4, 1, 0.5))
  
  ## Define the parameters for the peak density method
  pdp <- PeakDensityParam(sampleGroups = xdata$sample_group,
                          minFraction = 0.4, bw = 8)
  plotChromPeakDensity(xdata, mz = mzr, col = cols, param = pdp,
                       pch = 16, xlim = rtr)
  
  ## Use a different bw
  pdp <- PeakDensityParam(sampleGroups = xdata$sample_group,
                          minFraction = 0.4, bw = 5)
  plotChromPeakDensity(xdata, mz = mzr, col = cols, param = pdp,
                       pch = 16, xlim = rtr)
  
  ## Once again use a different set of parameters
  pdp <- PeakDensityParam(sampleGroups = xdata$sample_group,
                          minFraction = 0.5, bw = 4, binSize = 0.01)
  plotChromPeakDensity(xdata, mz = mzr, col = cols, param = pdp,
                       pch = 16, xlim = rtr)
  
  dev.off()
}
parallel::stopCluster(cl)

## plot shows peak density correspondence
#Upper panel: chromatogram for an mz slice with multiple chromatographic peaks. Middle and lower panel: identified chromatographic peaks at their retention time (x-axis) and index within samples of the experiments (y-axis) for different values of the bw parameter. The black line represents the peak density estimate. Grouping of peaks (based on the provided settings) is indicated by grey rectangles.

#The upper panel in the plot above shows the extracted ion chromatogram for each sample with the detected peaks highlighted. The middle and lower plot shows the retention time for each detected peak within the different samples. The black solid line represents the density distribution of detected peaks along the retention times. Peaks combined into features (peak groups) are indicated with grey rectangles. Different values for the bw parameter of the PeakDensityParam were used: bw = 30 in the middle and bw = 20 in the lower panel. In the example provided in the vignette, with the default value for the parameter bw the two neighboring chromatographic peaks would be grouped into the same feature, while with a bw of 20 they would be grouped into separate features. This grouping depends on the parameters for the density function and other parameters passed to the algorithm with the PeakDensityParam.

## Perform the correspondence
pdp <- PeakDensityParam(sampleGroups = xdata$sample_group,
            minFraction = 0.4, bw = 20)
xdata <- groupChromPeaks(xdata, param = pdp)

# The results from the correspondence can be extracted using the featureDefinitions method, that returns a DataFrame with the definition of the features (i.e. the mz and rt ranges and, in column peakidx, the index of the chromatographic peaks in the chromPeaks matrix for each feature).

## Extract the feature definitions
featureDefinitions(xdata)

# The featureValues method returns a matrix with rows being features and columns samples. The content of this matrix can be defined using the value argument. Setting value = "into" returns a matrix with the integrated signal of the peaks corresponding to a feature in a sample. Any column name of the chromPeaks matrix can be passed to the argument value. Below we extract the integrated peak intensity per feature/sample.

head(featureValues(xdata, value = "into"))

# This feature matrix contains NA for samples in which no chromatographic peak was detected in the feature’s m/z-rt region. While in many cases there might indeed be no peak signal in the respective region, it might also be that there is signal, but the peak detection algorithm failed to detect a chromatographic peak.

xdata <- fillChromPeaks(xdata)
head(featureValues(xdata))

## Missing values before filling in peaks
apply(featureValues(xdata, filled = FALSE), MARGIN = 2,
      FUN = function(z) sum(is.na(z))) -> before_fillpeaks

## Missing values after filling in peaks
apply(featureValues(xdata), MARGIN = 2,
      FUN = function(z) sum(is.na(z))) -> after_fillpeaks

fillpeaks_stats <- merge(before_fillpeaks, after_fillpeaks, by = "row.names") %>% 
  rename(Samples = Row.names, Before = x, After = y)

fillpeaks_stats

## At last we perform a principal component analysis to evaluate the grouping of the samples in this experiment. Note that we did not perform any data normalization hence the grouping might (and will) also be influenced by technical biases.

## Extract the features and log2 transform them
ft_ints <- log2(featureValues(xdata, value = "into"))

## Perform the PCA omitting all features with an NA in any of the
## samples. Also, the intensities are mean centered.
pc <- prcomp(t(na.omit(ft_ints)), center = TRUE)

## Plot the PCA
cols <- group_colors[xdata$sample_group]
pcSummary <- summary(pc)

png("QC/15 - PCA.png", 
    width = 15, height = 7, units = "in", res = 1200)
plot(pc$x[, 1], pc$x[,2], pch = 21, main = "Non-normalized intensities", 
     xlab = paste0("PC1: ", format(pcSummary$importance[2, 1] * 100,
                   digits = 3), " % variance"),
     ylab = paste0("PC2: ", format(pcSummary$importance[2, 2] * 100,
                   digits = 3), " % variance"),
     col = "darkgrey", bg = cols, cex = 2)
grid()
text(pc$x[, 1], pc$x[,2], labels = xdata$sample_name, col = "darkgrey",
     pos = 3, cex = 1)
dev.off()


processHistory(xdata)
ph <- processHistory(xdata, type = "Retention time correction")
ph 
processParam(ph[[1]])

xset_conv <- as(xdata, "xcmsSet")
#xset_conv <- fillPeaks(xset_conv)
sampclass(xset_conv) <- gsub("^.*\\.", "", sampclass(xset_conv))


## MetaboAnalyst matrix
metaboanalyst_dat <- groupval(xset_conv, "medret", "into")
rownames(metaboanalyst_dat) <- groupnames(xset_conv, mzdec = 5, rtdec = 5)
metaboanalyst_dat <- rbind(group = as.character(phenoData(xset_conv)$class), metaboanalyst_dat)
colnames(metaboanalyst_dat) <- xset_conv@phenoData$sample_name
write.csv(metaboanalyst_dat, file='QC/PeakIntensityMatrix_MetaboAnalyst.csv')
head(metaboanalyst_dat)
tail(metaboanalyst_dat)

# Isomeric separation
# Check if the individually found peaks (dots) are separated in groups (rectangles) properly
devtools::source_url("https://gitlab.com/R_packages/chemhelper/raw/master/R/xcms_helpers.R")

analyze.xcms.group(xset_conv,
                   mz = xset_conv@peaks[,"mz"][1],
                   rt = xset_conv@peaks[,"rt"][1],
                   rt_tol_sample = 60,
                   mz_tol_sample = 0.1,
                   rt_tol_group = 60,
                   mz_tol_group = 0.1)

# 3D visualization
x = split(mz(raw_data), f = fromFile(raw_data))
y = split(intensity(raw_data), f = fromFile(raw_data))
z = (split(rtime(raw_data), f = fromFile(raw_data)))
dl <- data.frame(mz = unlist(x$`1`), int = unlist(y$`1`), rt = rep(z$`1`, (Biobase::listLen(x$`1`))))
p <- plot_ly(x = dl$mz, y = dl$int, z = as.matrix(dl$rt)) %>% add_surface() ## surface 3D plot
p
```

```{r MetaboAnalyst}
mSet <- InitDataObjects("pktable", "stat", FALSE)
mSet <- Read.TextData(mSet, "QC/PeakIntensityMatrix_MetaboAnalyst.csv", "colu", "disc")

dir.create("MetaboAnalyst")
setwd("MetaboAnalyst/")

mSet <- SanityCheckData(mSet)
mSet <- ReplaceMin(mSet);
mSet <- Normalization(mSet, rowNorm = "QuantileNorm", transNorm = "LogNorm", scaleNorm = "NULL", ratio = FALSE, ratioNum = 20)

mSet <- PlotNormSummary(mSet, imgName = "normalization_0_", format = "png", dpi = 600, width = 7)
mSet <- PlotSampleNormSummary(mSet, "sample_normalization_0_", "png", 600, width = 7)

mSet <- FC.Anal.unpaired(mSet, 2.0, 0)
mSet <- PlotFC(mSet, "fold_change_0_", "png", 600, width=7)

mSet <- Ttests.Anal(mSet, nonpar = T, threshp = 0.05, paired = FALSE, equal.var = TRUE)
mSet <- PlotTT(mSet, "ttest_0_", "png", 600, width = 7)

mSet <- Volcano.Anal(mSet, paired = FALSE, fcthresh = 2.0, cmpType = 0, 
                     percent.thresh = 0.75, nonpar = T, threshp = 0.05, 
                     equal.var = TRUE, pval.type = "raw")
mSet <- PlotVolcano(mSet, "volcano_0_", plotLbl = 1, "png", 600, width = 7)

mSet <- PCA.Anal(mSet)
mSet <- PlotPCAPairSummary(mSet, "pca_pair_0_", "png", 600, width = 7, pc.num = 8)
mSet <- PlotPCAScree(mSet, "pca_scree_0_", "png", 600, width = 7, scree.num = 8)
mSet <- PlotPCA2DScore(mSetObj = mSet, imgName = "pca_score2d_0_", format = "png", dpi = 600, 
                       width = 7, pcx = 1, pcy = 2, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPCA2DScore(mSetObj = mSet, imgName = "pca_score2d_1_", format = "png", dpi = 600, 
                       width = 7, pcx = 1, pcy = 3, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPCA2DScore(mSetObj = mSet, imgName = "pca_score2d_2_", format = "png", dpi = 600, 
                       width = 7, pcx = 2, pcy = 3, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPCALoading(mSet, "pca_loading_0_", "png", dpi = 600, width = 7, inx1 = 1, inx2 = 2, plotType = "scatter", lbl.feat = 1)
mSet <- PlotPCABiplot(mSet, "pca_biplot_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2)
mSet <- PlotPCA3DScoreImg(mSet, "pca_score3d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, inx3 = 3, angl = 40)

mSet <- PLSR.Anal(mSet, reg = TRUE)
mSet <- PlotPLSPairSummary(mSet, "pls_pair_0_", "png", 600, width = 7, pc.num = 8)
mSet <- PlotPLS2DScore(mSet, "pls_score2d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPLS2DScore(mSet, "pls_score2d_1_", "png", 600, width = 7, inx1 = 1, inx2 = 3, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPLS2DScore(mSet, "pls_score2d_2_", "png", 600, width = 7, inx1 = 2, inx2 = 3, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotPLS3DScoreImg(mSet, "pls_score3d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, inx3 = 3, angl = 40)
mSet <- PlotPLSLoading(mSet, "pls_loading_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, "scatter", lbl.feat = 1);
mSet <- PLSDA.CV(mSet, "LOO", 8, "Q2")
mSet <- PlotPLS.Classification(mSet, "pls_cv_0_", "png", 600, width = 7)
mSet <- PlotPLS.Imp(mSet, "pls_imp_0_", "png", 600, width = 7, type = "vip", "Comp. 1", 10, FALSE)

mSet <- SPLSR.Anal(mSet, comp.num = 8, var.num = 10, "same")
mSet <- PlotSPLSPairSummary(mSet, "spls_pair_0_", "png", 600, width = 7, pc.num = 8)
mSet <- PlotSPLS2DScore(mSet, "spls_score2d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotSPLS3DScoreImg(mSet, "spls_score3d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, inx3 = 3, angl = 40)
mSet <- PlotSPLSLoading(mSet, "spls_loading_0_", "png", 600, width = 7, inx = 1, viewOpt = "overview")
mSet <- PlotSPLSDA.Classification(mSet, "spls_cv_0_", "loo", "png", 600, width = 7)

mSet <- OPLSR.Anal(mSet, reg = TRUE)
mSet <- PlotOPLS2DScore(mSet, "opls_score2d_0_", "png", 600, width = 7, inx1 = 1, inx2 = 2, reg = 0.95, show = 1, grey.scale = 0)
mSet <- PlotOPLS.Splot(mSet, "opls_splot_0_", "png", 600, width = 7, plotType = "all")
mSet <- PlotOPLS.MDL(mSet, "opls_mdl_0_", "png", 600, width = 7)
mSet <- PlotOPLS.Permutation(mSet, "opls_perm_1_", "png", 600, num = 2000, width = 7)

mSet <- PlotHeatMap(mSet, "heatmap_0_", "png", dpi = 600, width = 7, 
                    dataOpt = "norm", scaleOpt = "row", smplDist = "euclidean", 
                    clstDist = "ward.D", palette = "bwm", viewOpt = "overview", 
                    rowV = T, colV = T, var.inx = NA, border = T, grp.ave = F)
mSet<-PlotSubHeatMap(mSet, "heatmap_1_", "png", 600, width = 7, "norm", "row", "euclidean", "ward.D", "bwm", 
                     method.nm = "tanova", top.num = 25, "overview", T, T, T, F)
mSet<-PlotSubHeatMap(mSet, "heatmap_2_", "png", 600, width = 7, "norm", "row", "euclidean", "ward.D", "bwm", 
                     method.nm = "vip", top.num = 25, "overview", T, T, T, F)

mSet <- RF.Anal(mSet, treeNum = 5000, tryNum = 20, randomOn = 1)
mSet <- PlotRF.Classify(mSet, "rf_cls_1_", "png", 600, width = 7)
mSet <- PlotRF.VIP(mSet, "rf_imp_1_", "png", 600, width = 7)
mSet <- PlotRF.Outlier(mSet, "rf_outlier_1_", "png", 600, width = 7)

mSet <- SaveTransformedData(mSet)
mSet <- PreparePDFReport(mSet, "CCP")

setwd("../")
```

```{r Significant Features}
stat.files <- list.files(path = "MetaboAnalyst", pattern = "plsda_vip.csv|volcano.csv|t_test.csv|splsda_loadings.csv", full.names = T)
stat.res <- lapply(stat.files, read.csv, check.names = F) %>% setNames(., stat.files %>% basename)
```
"Derivative signals such as isotopes, adducts, dimers and fragments, can be automatically annotated by correlation analysis on both signal shape and intensity patterns using software tools like CAMERA, PUTMEDID-LCMS and mzMatch. Such peaks are not discarded, but only flagged, so that their assigned annotations can be taken into account in the metabolite identification step."

We want to answer the questions which peaks occur from the same molecule and secondly compute its exact mass and annotate the ion species.
```{r Isotope, adduct, and fragment detection/annotation, isotope decomposition, and neutral loss exploration}
#Create an xsAnnotate object / create pseudospectra and perform isotope clster detection
xsa <- xsAnnotate(xset_conv, polarity = "positive", sample = c(1:dim(xset_conv@phenoData)[1]))

#Group after RT value of the xcms grouped peak / group peaks by retention time
xsaF <- groupFWHM(object = xsa, perfwhm = 0.1, intval = "into")
# this function uses the retention time information. Every peaks that falls into a defined window are considered as one group. The window is defined as a percentage of the peak FWHM around the RT med value
# The perfwhm parameter defines the window width, which is used for matching. Lower it for a smaller windows or set it to a higher value, if the retention time varies.

#Verify grouping
xsaC <- groupCorr(object = xsaF, 
                  calcIso = FALSE, 
                  calcCiS = FALSE,
                  calcCaS = TRUE, 
                  cor_eic_th = 0.7, 
                  cor_exp_th = 0.7,
                  pval = 0.000001,
                  graphMethod = "lpc",
                  intval = "into")
# This function calculates the pearson correlation coefficient based on the peak shapes of every peak in the pseudospectrum to separate co-eluted substances. Run groupFWHM before groupCorr to avoid extremely long running times

# if your analysis doesn’t need annotations, only a separation into groups, then simply stop after groupCorr

#Annotate isotopes (isotopic peaks), could be done before groupCorr
xsaFI <- findIsotopes(object = xsaC, ppm = 10, mzabs = 0.02, intval = "into")
# maxcharge and maxiso control the maximum number of the expected isotopes within one cluster and their charges

# CAMERA can identify isotope peaks within every pseudospectra. In particular, putative isotope clusters are validated and deconvoluted based on database statistics of the KEGG database
# an <- findIsotopesWithValidation(object = xsaF, 
#                                  ppm = 10, mzabs = 0.01, 
#                                  intval="intb", maxcharge = 3, 
#                                  validateIsotopePatterns = T, database = compoundLibraries()[5])

# Rule tables in CAMERA, more info can be found in `vignette("CAMERA")`

rules.primary.pos <- system.file('rules/primary_adducts_pos.csv', package = "CAMERA") %>% read.csv
rules.primary.neg <- system.file('rules/primary_adducts_neg.csv', package = "CAMERA") %>% read.csv
rules.extended.pos <- system.file('rules/extended_adducts_pos.csv', package = "CAMERA") %>% read.csv(sep = "\t")
rules.extended.neg <- system.file('rules/extended_adducts_neg.csv', package = "CAMERA") %>% read.csv

rules.pos.common <- commonMZ::MZ_CAMERA(mode = "pos", warn_clash = TRUE, clash_ppm = 5) %>% as.data.frame
rules.neg.common <- commonMZ::MZ_CAMERA(mode = "neg", warn_clash = TRUE, clash_ppm = 5) %>% as.data.frame

#Annotate adducts
xsaFA <- findAdducts(xsaFI, polarity = "positive", ppm = 10, mzabs = 0.02, multiplier = 4)
xsaFA_extended <- findAdducts(xsaFI, polarity = "positive", ppm = 10, mzabs = 0.02, multiplier = 4, rules = rules.extended.pos)
xsaFA_commonMZ <- findAdducts(xsaFI, polarity = "positive", ppm = 10, mzabs = 0.02, multiplier = 4, rules = rules.pos.common)
## CAMERA calculates its own rule table depending on your ionization mode
## However, 'rules' parameter can be set (CAMERA contains four precalculated rule tables)
## e.g. rules = read.csv(system.file('rules/primary_adducts_pos.csv', package = "CAMERA"))

rules_count_extended <- xsaFA_extended@annoID[, "ruleID"] %>% 
      factor(levels=1:nrow(rules.extended.pos)) %>% 
      table %>% as.matrix %>% as.data.frame %>% 
      bind_cols(rules.extended.pos[,'name',drop=FALSE],.) %>% 
      setNames(c("Rule","Count")) %>% 
      arrange(desc(Count)) %>% 
      as.data.frame
pie(as.numeric(rules_count_extended[,"Count"]),labels=rules_count_extended[,"Rule"])

rules_count_common <- xsaFA_commonMZ@annoID[, "ruleID"] %>% 
      factor(levels=1:nrow(rules.pos.common)) %>% 
      table %>% as.matrix %>% as.data.frame %>% 
      bind_cols(rules.pos.common[,'name',drop=FALSE],.) %>% 
      setNames(c("Rule","Count")) %>% 
      arrange(desc(Count)) %>% 
      as.data.frame
pie(as.numeric(rules_count_common[,"Count"]),labels=rules_count_common[,"Rule"])

#Get final peaktable and store on harddrive / ## extract annotated peak table
xsaPL <- getPeaklist(xsaFA)
xsaPL_extended <- getPeaklist(xsaFA_extended)
xsaPL_common <- getPeaklist(xsaFA_commonMZ)

## pcgroup shows the annotation group / column pc shows the result of the peak correlation based annotation (independent of the annotations iso and adduct). Peaks with the same label are supposed to belong to the same spectrum

## The column adduct shows the annotation hypotheses for the ions species. The value after the brackets is the estimated molecular mass.

## The column isotopes contains the annotated isotopes for a monoisotopic peak. The values in the first square brackets denote the isotope-group-id(column id), the second is the isotope annotation and the number after the brackets is the charge of the isotope.

## Extract only those features that were found to be significantly different between groups via MetaboAnalyst analysis
sig_feat <- c(658.4816, 629.4534, 651.5637, 674.5819, 732.5720, 667.1389, 387.1131, 846.5442)
xsaPL %>% 
  dplyr::filter(paste0("abs(mz-", sig_feat, ") < 0.0001", collapse = " | ") 
                %>% parse(text = .) %>% as.expression %>% eval())

sample_groups <- paste(unique(xsaFA@xcmsSet@phenoData$sample_group), collapse = "_")
write.csv(xsaPL, file = paste0(sample_groups, 
                               "adducts_isotopes_fragments_annotated.csv"))

diffrep <- diffreport(xset_conv, 
                      class1 = levels(sampclass(xset_conv))[1],
                      class2 = levels(sampclass(xset_conv))[2], 
                      filebase = "diffreport_ESI", eicmax = 50, 
                      sortpval = FALSE, ## this is very important
                      metlin = 0.5, mzdec = 5)

xsa.peaklist <- xsaPL
diffrep.new <- cbind(diffrep, xsa.peaklist[, c("isotopes", "adduct","pcgroup")])
diffrep.new <- diffrep.new[order(diffrep.new[,"pvalue"]),] #Sort after pvalue

plotEICs(xsaFA, pspec = 2, maxlabel = 5)
plotPsSpectrum(xsaFA, pspec = 2, maxlabel = 5)
plotEICs(xsaFA,1) # Plot all peak EICs of pseudospectrum 1

# plotPsSpectrum plots the spectrum of a pseudospectrum, labelling the most intense peaks
# Plot the spectrum of pseudospectrum 1 and highlight the
# annotation and mz labels of the 10 strongest peaks
plotPsSpectrum(xsaFA, 1, maxlabel = 10)


## annotate is a wrapper function for the annotation workflow. It runs groupFWHM, findIsotopes, groupCorr and findAdducts in order as mentioned.

#A full annotation run
xsa <- CAMERA::annotate(xset_conv, perfwhm = 0.6, 
                        cor_eic_th = 0.75, ppm = 5, polarity="positive", 
                        sample = c(1:dim(xset_conv@phenoData)[1]))

peaklist <- getPeaklist(xsa)
write.csv(peaklist, file = "results.csv")




#Make a diffreport with CAMERA result / running fillPeaks in advance is necessary
diffreport <- annotateDiffreport(xset_conv) # wrapper function for the xcms diffreport and the annotate function
write.csv(diffreport, file="diffreport.csv")


# A common strategy to identify interesting compounds is the screening after specific neutral losses. CAMERA adopts this strategy and provides with findNeutralLoss and findNeutralLossSpecs an interface for scanning every pseudospectrum for neutral losses. The difference between both methods is in the results. findNeutralLossSpecs returns an artificial xcmsSet containing the peaks, which have the neutral loss. findNeutralLossSpecs returns a boolean vector for every pseudospectrum, where a hit is marked with TRUE.

# The function needs a xsAnnotate object after groupCorr or groupFWHM

# Let's search for peaks with water loss
nloss.pseudo.xset <- findNeutralLoss(xsaF, mzdiff = 18.01, mzabs = 0.01) # The method searches in every pseudospectra for a distance between two ions matching a provided mass difference. 

nloss.pseudo.spect <- findNeutralLossSpecs(xsaF, mzdiff = 18.01, mzabs = 0.01)

head(nloss.pseudo.xset@peaks) #show hits
head(nloss.pseudo.spect)

## Extracting isotope clusters/annotations

isolist <- getIsotopeCluster(xsaFI) # extracts the isotope annotation from a xsAnnotate object
isolist[[10]] # get IsotopeCluster 10

isolist.multiple <- getIsotopeCluster(xsaFI, sampleIndex=c(1,2,5,7,9)) # Select from multiple samples


## Interaction with Rdisop for calculation of molecular composition

isotopes.decomposed <- lapply(isolist.multiple,function(x) {
  Rdisop::decomposeIsotopes(x$peaks[,1],x$peaks[,2],z=x$charge);
}) #decomposed isotope cluster, filter steps are recommended

length(isotopes.decomposed)
head(isotopes.decomposed[[1]])
```

```{r Contaminant annotation in CAMERA}
positive_rule <- system.file('extdata/CAMERA_rules_pos.xlsx', package = "commonMZ")
negative_rule <- system.file('extdata/CAMERA_rules_neg.xlsx', package = "commonMZ")
EI_mode_rule <- system.file('extdata/CAMERA_rules_EI.xlsx', package = "commonMZ")

positive_rule <- as.data.frame(readxl::read_xlsx(positive_rule))
negative_rule <- as.data.frame(readxl::read_xlsx(negative_rule))
EI_mode_rule <- as.data.frame(readxl::read_xlsx(EI_mode_rule))

xsaFA_con <- findAdducts(xsaFI, polarity = "positive", rules = as.data.frame(positive_rule))
xsaPL_contamination <- getPeaklist(xsaFA_con)

### Another way of doing it:

contaminant_rules <- commonMZ::MZ_CAMERA(mode = "pos", warn_clash = T, clash_ppm = 5)
contaminant_rules_df <- as.data.frame(contaminant_rules)
xsaFA_cntm <- findAdducts(xsaFI, polarity = "positive", rules = contaminant_rules_df)
found_adduct_contaminants <- getPeaklist(xsaFA_cntm)
found_adduct_contaminants %>% distinct(adduct) %>% head(n = 15)
```

```{r Atom count expectation and isotope cluster validation}
# Here, we compute quantiles for the ratio between the isotopes of database-specific sets of substances resulting in confidence intervals of isotope ratios. We check whether the ratios between the peaks of a putative isotope cluster are within the calculated confidence intervals and deconvolute the putative isotope cluster otherwise.

# There are at least four cases for which the validation of isotope clusters can be beneficial:

# First, valid isotope clusters can be verified which strengthens the trust in the data. 

# Second, multiple coeluting substances with mass differences of a few dalton can result in isobaric ion species and thus in overlapping isotope clusters. These are potentially misinterpreted as a single isotope cluster affecting downstream analyses. This necessitates the deconvolution of the overlapping isotope cluster into at least two valid isotope clusters. 

# Third, substances can be affected by hydrogen loss. This leads to mass differences similar to isotope peaks and can result in a small trailing peak which is potentially misinterpreted as monoisotopic peak of the putative isotope cluster. This may result in the assumption of a wrong monoisotopic mass and may even lead to the rejection of the entire isotope cluster on the basis of failed intensity-checks. Although this small trailing peak corresponds to the same substance, it needs to be removed from the isotope cluster in order to allow more precise molecular formula predictions. 

# Fourth, the intensity of small peaks is systematically underestimated by some mass spectrometers which leads to distorted ratios between different isotope peaks as reported previously in Boecker et al. 2009. This intensity bias would lead to distorted molecular formula predictions and the removal of these underestimated peaks from the isotope cluster allows more precise molecular formula predictions.

cpObj <- compoundQuantiles(compoundLibrary = "kegg")

## meta information
print(paste("Available libraries = {", paste(compoundLibraries(), collapse = ", "), "}", sep = ""))
print(paste("Compound library = ", cpObj@compoundLibrary, sep = ""))
print(paste("Available mass window sizes = {", paste(massWindowSizes(cpObj@compoundLibrary), collapse = ", "), "}", sep = ""))
print(paste("Mass window size = ", cpObj@massWindowSize, sep = ""))
print(paste("Elements = {", paste(cpObj@elementSet, collapse = ", "), "}", sep = ""))
print(paste("Isotopes = {", paste(cpObj@isotopeSet, collapse = ", "), "}", sep = ""))
print(paste("Mass interval = [", cpObj@minCompoundMass, ", ", cpObj@maxCompoundMass, "] Da; #mass windows = ", cpObj@numberOfMassWindows, " a ", cpObj@massWindowSize, "Da", sep = ""))
print(paste("Quantile levels = {", paste(cpObj@quantileSet, collapse = ", "), "}", sep = ""))

## examples
compoundMass <- 503 # mass of the compound is 503 Da
quantileLow <- 0.05 # 5% (lower quantile)
quantileHigh <- 0.95 # 95% (higher quantile)

## example for element count
element <- "C" # the element is Carbon
countLow <- getAtomCount(object = cpObj, element = element, mass = compoundMass, quantile = quantileLow)
countHigh <- getAtomCount(object = cpObj, element = element, mass = compoundMass, quantile = quantileHigh)
print(paste("The ", (quantileHigh - quantileLow) * 100, "% confidence interval for the number of atoms of element ", element, " in a compound with mass ", compoundMass, " is [", countLow, ", ", countHigh, "]", sep = ""))

# getAtomCount returns the expected number of atoms (countLow and countHigh) of the given element in a compound of the given mass for the given quantiles

## example for isotope proportion
isotope1 <- 0
isotope2 <- 1
propLow <- getIsotopeProportion(object = cpObj, isotope1 = isotope1, isotope2 = isotope2, mass = compoundMass, quantile = quantileLow)
propHigh <- getIsotopeProportion(object = cpObj, isotope1 = isotope1, isotope2 = isotope2, mass = compoundMass, quantile = quantileHigh)
print(paste("The ", (quantileHigh - quantileLow) * 100, "% confidence interval for the proportion of isotopes ", isotope1, " / ", isotope2, " in a compound with mass ", compoundMass, " is [", propLow, ", ", propHigh, "]", sep = ""))
```

```{r QC4Metabolomics}
git2r::clone(url = "https://github.com/stanstrup/QC4Metabolomics.git")

# First, set up the database in MySQL
# $ sudo /etc/init.d/mysql start
# $ sudo /usr/bin/mysql -u root -p
#   mysql> CREATE DATABASE QC4MetabolomicsR;
#   mysql> GRANT ALL PRIVILEGES ON *.* TO 'R_user'@'localhost' IDENTIFIED BY 'pass12345678';

library(MetabolomiQCsR)
MetabolomiQCsR.env$db$db <- "QC4MetabolomicsR"
MetabolomiQCsR.env$db$user <- "R_user"
MetabolomiQCsR.env$db$password <- "pass12345678"
MetabolomiQCsR.env$db$host <- "127.0.0.1"

setwd("./QC4Metabolomics/Shiny App")
source("../init/init_db.R")

shiny::runApp(launch.browser = T)
```

```{r Sample information and experiment metadata}
xml.path <- "Raw/Mzb1/ESI+"

## Sample information / extracted from sample_info.xml files in .d folders ##

sample_info_pos <- list.files(path = xml.path, pattern = "sample_info.xml", 
                              all.files = T, full.names = T, recursive = T)

sample_info <- list(NULL)
sample_info <- lapply(sample_info_pos, XML::xmlToDataFrame)

#sample_info[[1]] %>% 
#  dplyr::select(DisplayName, Value) %>% 
#  filter(DisplayName %in% c("Sample Name", "Sample Position", 
#                            "Method", "Inj Vol (µl)", "Equilib Time (min)", 
#                            "Dilution", "Acquisition Time", "Operator Name"))

sample_info_extracted <- lapply(sample_info, function(exdata){
  exdata %>% 
    dplyr::select(DisplayName, Value) %>% 
    filter(DisplayName %in% 
             c("Sample Name", "Sample Position", "Method", 
               "Inj Vol (µl)", "Equilib Time (min)", "Dilution", 
               "Acquisition Time", "Operator Name"))})

for(i in 1:length(sample_info_extracted)){
  names(sample_info_extracted)[i] <- sample_info_extracted[[i]]$Value[1]
  names(sample_info_extracted[[i]])[2] <- sample_info_extracted[[i]]$Value[1]
}

sample_info_extracted <- Reduce(function(x, y) merge(x, y, all=TRUE, by = "DisplayName"), 
                                sample_info_extracted) %>% t() %>% as.data.frame()

for(i in 1:length(sample_info_extracted)) { sample_info_extracted[,i] <- as.character(sample_info_extracted[,i]) }
names(sample_info_extracted) <- sample_info_extracted[1,]
sample_info_extracted <- sample_info_extracted[-1,]


## Job/experiment information/metadata (Worklist files) ##

worklist_pos <- list.files(path = xml.path, pattern = "Worklist.xml", ## Worklist.xml files in .d folders -- 
                           ### these do not seem to be useful and consistent.. e.g. the order of running samples is outlined differently in each file!
                              all.files = T, full.names = T, recursive = T)

main_worklist_file <- "Raw/Freezing_Exp_All/170726 Mrazici Experiment.wkl" ## these are the main worklist files found in the QTOF_WORKLIST folder and according to Karel should be the correct ones


#worklist <- list(NULL)
#worklist <- lapply(worklist_pos, XML::xmlToDataFrame)
#f <- XML::xmlParse(worklist_pos[1])
#getNodeSet(f, "//JobDataList")
#xmlToDataFrame( getNodeSet(xmlRoot(f) , "//JobData") )


worklist_xml <- lapply(worklist_pos, XML::xmlParse)
main_worklist <- XML::xmlParse(main_worklist_file)

extract_worklist <- function(f){
  data.frame(
    Name = xmlToDataFrame( getNodeSet(xmlRoot(f) , "//JobData//Name"))$text,
    InjectionVol = xmlToDataFrame( getNodeSet(xmlRoot(f) ,"//JobData//InjectionVolume"))$text,
    AcqTime = xmlToDataFrame( getNodeSet(xmlRoot(f) ,"//JobData//AcqTime"))$text,
    EquilibrationTime = xmlToDataFrame( getNodeSet(xmlRoot(f), "//JobData//EquilibrationTime"))$text,
    SamplePosition = xmlToDataFrame( getNodeSet(xmlRoot(f) ,"//JobData//SamplePosition"))$text,
    DilutionFactor = xmlToDataFrame( getNodeSet(xmlRoot(f) , "//JobData//DilutionFactor"))$text,
    AcqMethod = xmlToDataFrame( getNodeSet(xmlRoot(f) , "//JobData//AcqMethod"))$text
  )}

experiment_metadata <- lapply(worklist_xml, FUN = extract_worklist)
experiment_metadata_main <- extract_worklist(main_worklist)

```

```{r Missing data treatment; mixture model analysis with metabomxtr}
# An underused approach for metabolite-by-metabolite analysis is the Bernoulli/lognormal mixture model proposed by Moulton and Halsey (1995). This method simultaneously estimates parameters modeling the probability of non-missing response and the mean of observed values. Imputation is not required, and instead ‘missingness’ is explicitly modeled as either true absence or presence below detectability, consistent with non-targeted metabolomics technology.

# The R package metabomxtr has been developed to facilitate mixture-model analysis of non-targeted metabolomics data in which only a portion of samples have quantifiable abundance for certain metabolites.

### The package is advertised for 'normally-distributed' metabolite abudances/intensities.
### Seemingly, this package heavily depends on "NA" values and a certain number of NA values are required in each metabolite column, if there are no NA values, it does not work!
### It also does not work well with 3 sample groups. 2 is the maximum

### The example in the vignette reads: Each of the metabolites [in metabdata] contains missing values and the data look fairly normal, so mixture model analysis seems appropriate.

# Missing values can be due to the true absence of the metabolite in the sample or presence at a level below detectability. Mixture model analysis can formally account for metabolite missingness due to absence or undetectability.

### We can use the peak intensity matrix that was generated for MetaboAnalyst
### However, samples should be in rows and metabolites in columns
### Two additional columns are needed to specify 'phenotype' group and 'batch' (run) number

## Q: Can we instead (of batch run number) use some other information from the tables generated above? (experiment_metadata and sample_info). IN PROGRESS. WILL BE INVESTIGATED BELOW.
## Several columns included in data(metabdata) can perhaps give a better idea on what sort of information can be used

metabomxtr_table <- as.data.frame(t(metaboanalyst_dat))
names(metabomxtr_table)[grep(pattern = "group", x = names(metabomxtr_table))] <- "phenotype"

## log-transform intensity values (is this needed/recommended?)
for(i in 2:length(metabomxtr_table)){metabomxtr_table[,i] <- as.numeric(as.character(metabomxtr_table[,i]))}
metabomxtr_table_not_transformed <- metabomxtr_table
metabomxtr_table[,-1] <- log2(metabomxtr_table[,-1]) ### this results in 'errors' when running the mxtrmod function.. Probably not always the correct approach to transformation

#metabomxtr has two main functions: mxtrmod and mxtrmodLRT. mxtrmod executes mixture models, taking as inputs response variable names, a model formula and a data object (a matrix of values with NA to indicate missingness or an ExpressionSet R object). It returns optimized parameter estimates and the corresponding negative log likelihood value. Parameter vectors α and β are estimated using maximum likelihood using the optimx package. By default, T is set to the minimum observed metabolite abundance.

head(sample_info_extracted)
head(metabomxtr_table[,1:5])

# make sure sample names are row.names and are in the same format in both datasets
metabomxtr_table_complete <- merge(sample_info_extracted, metabomxtr_table, by="row.names")
names(metabomxtr_table_complete)[1] <- "SampleNames"
head(metabomxtr_table_complete[,1:20])


# these are only test runs and experiments, they might not make any sense, 
# e.g. adding SampleNames to the model is senseless.
# the model works better without SampleNames and Dilution

# Phenotype will be usually our main predictor of interest. Our goal will be to determine whether one group has significantly different metabolite leveles compared to the other group.

class(metabomxtr_table_complete$phenotype) # must return factor
levels(metabomxtr_table_complete$phenotype)
metabomxtr_table_complete$phenotype <- relevel(metabomxtr_table_complete$phenotype, ref="WT") # set the reference group
table(metabomxtr_table_complete$phenotype)

# Next, we need to specify the full mixture model. This should be of the form ∼ x1+x2...|z1+z2..., where x’s represent covariates modeling metabolite presence/absence (discrete portion), and z’s are covariates modeling the mean of observed values (continuous portion). The predictor of interest should be included in both the discrete and continuous portions of the full model. In addition, we’ll control for variables such as age, gestational age, sample storage time, and parity in the continuous portion.

# remember removeMissingLevels and removeAllMissingCatVar when including categorical variables in the model

test_model_full <- ~ phenotype | phenotype + as.character(SampleNames) + as.character(`Acquisition Time`) + 
  as.numeric(as.character(Dilution)) + as.numeric(as.character(`Inj Vol (µl)`)) + as.character(`Sample Position`)

test_model_reduced <- ~ 1 | as.character(SampleNames) + as.character(`Acquisition Time`) + 
  as.numeric(as.character(Dilution)) + as.numeric(as.character(`Inj Vol (µl)`)) + as.character(`Sample Position`)

# adding 'character' variables to the model results in a model without 'xInt'...

# metabolite_names <- names(metabomxtr_table_complete)[11:length(metabomxtr_table_complete)]
### length(metabomxtr_table_complete) should be most probably changed to a much smaller number. It does not seem to make any sense to use 'all' detected features. Perhaps we should keep only those that are truly significant or those features that are of interest (after metabolite detection and statistical analysis). It also seems that a high number of metabolites causes an error (or maybe the error caused by something else)

# a better option would be something like this:
required_NA_proportion <- ceiling(nrow(metabomxtr_table_complete) * 0.2)
metabolite_names <- names(which(colSums(is.na(metabomxtr_table_complete)) >= required_NA_proportion))

test_run_full <- mxtrmod(ynames = metabolite_names, 
                         mxtrModel = test_model_full, data = metabomxtr_table_complete)

test_run_reduced <- mxtrmod(ynames = metabolite_names, mxtrModel = test_model_reduced,
                            data = metabomxtr_table_complete, fullModel = test_model_full) # note the importance of specifying the fullModel parameter when running reduced models, which ensures that if model covariates have missing values, both full and reduced model results are based on the same set of observations. 

# In the output data frame, 
# .id column indicates metabolite, 
# columns beginning with x’s are parameter estimates for the discrete portion of the model, 
# columns beginning with z’s are parameter estimates for the continuous portion, 
# sigma is the variance of observed values, 
# method is the optimization algorithm used, 
# conv indicates whether the model converged (0=convergence), 
# negLL is the negative log likelihood, 
# nObs is the number of observations used.

# the significance of full vs. reduced models can be examined using nested likelihood ratio chi-squared tests
finalResult <- mxtrmodLRT(test_run_full, test_run_reduced, adj = "BH")

# negLLFull is the negative log likelihood of the full model, 
# negLLRed is the negative log likelihood of the reduced model, 
# chisq is the test statistic
# low p-values = metabolite levels are significantly different between groups

## result table

# calculate the estimated proportion of metabolites present for each phenotype group

fullModelResults <- test_run_full
x_phen <- grep("x_phenotype", names(fullModelResults), value = T)
z_phen <- grep("z_phenotype", names(fullModelResults), value = T)
first_phenotype <- round(exp(fullModelResults$xInt + fullModelResults[x_phen]) / 
                        (1 + exp(fullModelResults$xInt + fullModelResults[x_phen])), digits = 2)
second_phenotype <- round(exp(fullModelResults$xInt) / (1+exp(fullModelResults$xInt)), digits = 2)

# calculate the estimated mean metabolite levels by phenotype group, and estimated mean difference

first_phenotype.mean <- round(fullModelResults$zInt + fullModelResults[z_phen], digits = 2)
second_phenotype.mean <- round(fullModelResults$zInt, digits=2)
phen.mean.diff <- round(fullModelResults[z_phen], digits=2)

# combine with metabolite names and FDR-adjusted p-values.

finalResultTable <- data.frame(Metabolite = fullModelResults$.id,
                               first_phenotype = first_phenotype,
                               second_phenotype = second_phenotype,
                               first_phenotype.mean = first_phenotype.mean,
                               second_phenotype.mean = second_phenotype.mean,
                               phen.mean.diff = phen.mean.diff,
                               FDR.Adj.P = round(finalResult$adjP,digits=4))
finalResultTable
```

```{r Normalization with mixture models}
# Controlling technical variability in metabolite abundance, or normalization, is a critical step in the analysis and interpretation of non-targeted gas-chromatography/mass-spectrometry (GC/MS) data. In large scale metabolomics studies requiring sample processing in many analytic batches, technical artifacts due to batch and run-order within batch are common. In these cases, repeated assays of a set of control samples may be used to estimate and account for these artifacts. The metabomxtr package implements a mixture model normalization approach via the function mixnorm for studies implementing this quality control measure. Based on control sample variability, mixnorm allows for per-metabolite modeling of both batch and run-order effects, while allowing for bach specific thresholds of metabolite detectability.

# euMetabCData is a data frame containing GC/MS data from separate mom and baby control pools. Control pool aliquots were run at the beginning, middle and end of each batch with placement indicated by -1, -2 and -3 appended to the sample name, respectively.

# select metabolites of interest
required_NA_proportion <- ceiling(nrow(metabomxtr_table_complete) * 0.2)
metabolite_names <- names(which(colSums(is.na(metabomxtr_table_complete)) >= required_NA_proportion))
ynames <- c("M57.97570T44.13454", "M57.97464T1158.43262",
            "M59.01369T47.62086", "M59.97107T44.23310")

## in progress...
# https://bioconductor.org/packages/release/bioc/vignettes/metabomxtr/inst/doc/mixnorm_Vignette.pdf
# https://bioconductor.org/packages/release/bioc/vignettes/metabomxtr/inst/doc/mixnorm_Vignette.R
```

```{r Outlier detection}
outlier_info <- metabomxtr::addOutlierInfo(metab.col = "M310.09596T61.92001", metabomxtr_table_complete, outlier.sd.thresh = 2)
outlier_info[c("SampleNames","M310.09596T61.92001", "outlier")]
```

```{Normalization by internal standard}
# normalizeByInternalStandard requires a very stricit data format
# first column = metabolite names
# first row = volume (e.g. 4ul)

metaboanalyst_df <- metaboanalyst_dat[-1,] %>% as.data.frame # remove group labels in the first row
metaboanalyst_df$Name <- rownames(metaboanalyst_df) # add metabolite names as a column
len_df <- length(metaboanalyst_df)
for(i in 1:len_df) {metaboanalyst_df[,i] <- as.character(metaboanalyst_df[,i])}
metaboanalyst_df <- metaboanalyst_df[,c(len_df, 1:len_df-1)] # move the name column to the beginning of the df

injection_vol <- sample_info_extracted[,"Inj Vol (µl)", drop = F][rownames(sample_info_extracted[,"Inj Vol (µl)", drop = F]) %in% names(metaboanalyst_df)[-1], , drop = FALSE]
injection_vol <- injection_vol[ order(names(metaboanalyst_df)[-1]), ] %>% paste0("ul")

metaboanalyst_df <- rbind(c("Replicates", injection_vol),metaboanalyst_df) # sample volume row

metaboanalyst_df_internal_normalized <- Metab::normalizeByInternalStandard(inputData = metaboanalyst_df,
                                                                           internalStandard = "M71.01388T51.05411",
                                                                           save = F)

# Metab also offers a function named Metab::removeFalsePositives. It does not seem to be anything special. In general MetaboAnalyst is more sophisticated and we may not need to use this code chunk at all.
```

```{r Semi-parametric differential abundance analysis of non-normally distributed metabolomics data}
# The data may contain a large fraction of zero values and non-zero part may not be normally distributed. SDAMS considers a two-part semi-parametric model, a logistic regression for the zero proportion and a semi-parametric log-linear model for the non-zero values. A kernel-smoothed likelihood method is proposed to estimate regression coefficients in the two-part model and a likelihood ratio test is constructed for differential abundant analysis.

write.csv(x = metaboanalyst_dat[-1,], file = "feature.csv")
write.csv(x = metaboanalyst_dat[1,], file = "group.csv")
exp_df <- SDAMS::createSEFromCSV("feature_SDAMS_working_example.csv", "group_SDAMS_working_example.csv")

## easier one-liner approach
exp_mat <- SDAMS::createSEFromMatrix(metaboanalyst_dat[-1,], as.matrix(metaboanalyst_dat[1,]))
head(assay(exp_mat)[,1:10])
colData(exp_mat)$grouping

## run SDA / perform differential abundance analyais
SDA_results <- SDAMS::SDA(exp_df)
head(SDA_results$gamma) # The covariate effect on the fraction of zero values for feature g is γg. First element of this vector is for the first feature, second one for the second feature, etc.
head(SDA_results$pv_gamma) # p-values calculated from likelihood ratio test

# The corresponding hypothesis is H0: γg = 0 vs. H1: γg =/= 0.

head(SDA_results$qv_gamma) # results for γg

# The model parameter βg is the log fold change in the non-zero abundance comparing different values of the single group covariate for feature g. The corresponding two-sided hypothesis is H0: βg = 0 vs. H1: βg =/= 0. Again, SDA will return p-values and adjusted p-values(q-values) for parameter βg, and they are stored in pv_beta and qv_beta respectively.

head(SDA_results$beta)
head(SDA_results$pv_beta)
head(SDA_results$qv_beta)

head(SDA_results$pv_2part)
head(SDA_results$qv_2part)

head(SDA_results$feat.names) # feature names
```

```{r Identification of secondary metabolites}
# http://www.northenlab.org/research/secondary-metabolites/
# doi.org/10.1021/ac5014783
# http://facultyweb.mga.edu/yingfeng.wang/Assets/midas/midas.html
download.file("http://facultyweb.mga.edu/yingfeng.wang/research/metabolomics/midas/MIDAS.zip")
```

```{r Multi-batch integration}
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570768/
# doi:  10.1007/s11306-017-1248-1
```


```{r Batch Correction -- NOT FUNCTIONAL -- UNDER DEVELOPMENT}
devtools::install_git("https://gitlab.com/CarlBrunius/batchCorr.git")

path.pos <- "Data/Freezing_Exp_All/pos/"
pos.mzml <- list.files(path.pos, recursive = T, full.names = T, pattern=".mzML")
pos.mzml

param.ppm <- 30
param.snthresh <- 3
param.prefilter <- c(5, 10000)
param.noise <- 6500
param.peakwidth <- c(20, 50)
param.parallelization <- MulticoreParam(floor(detectCores() * 0.95)) ### use 90% of the cores for parallel computing

xset.batch <- xcmsSet(pos.mzml, method = "centWaveWithPredictedIsotopeROIs", 
                          ppm = param.ppm, 
                          snthresh = param.snthresh, 
                          prefilter = param.prefilter, 
                          noise = param.noise, 
                          peakwidth = param.peakwidth,
                          BPPARAM = param.parallelization)

xset.batch <- group(xset.batch)
xset.batch <- retcor(xset.batch, family="gaussian", plottype="mdevden")
xset.batch <- group(xset.batch)
xset.batch <- retcor(xset.batch, family="gaussian", plottype="mdevden")

QC_nofill <- group(xset.batch)
QC_fill <- fillPeaks(QC_nofill, method = "chrom")


# Organise into peaktable with missing data
    QCB = grabAlign(QC_nofill,batch='Fresh',grp='Mouse1')
    RefB=grabAlign(QC_nofill,batch='Fresh',grp='Mouse4')
    QCF=grabAlign(QC_nofill,batch='Frozen',grp='Mouse2')
    RefF=grabAlign(QC_nofill,batch='Frozen',grp='Mouse4')
    QCH=grabAlign(QC_nofill,batch='Refrozen',grp='Mouse5')
    RefH=grabAlign(QC_nofill,batch='Refrozen',grp='Mouse4')
    PTnofill=rbind(QCB,RefB,QCF,RefF,QCH,RefH)
    
# Organise into peaktable without missing data
    QCB = grabAlign(QC_fill,batch='Fresh',grp='Mouse1')
    RefB=grabAlign(QC_fill,batch='Fresh',grp='Mouse4')
    QCF=grabAlign(QC_fill,batch='Frozen',grp='Mouse2')
    RefF=grabAlign(QC_fill,batch='Frozen',grp='Mouse4')
    QCH=grabAlign(QC_fill,batch='Refrozen',grp='Mouse5')
    RefH=grabAlign(QC_fill,batch='Refrozen',grp='Mouse4')
    PTfill=rbind(QCB,RefB,QCF,RefF,QCH,RefH)
    
    # Set up metadata (Quick'n'Dirty approach)
    batch=c(rep('B',nrow(QCB)+nrow(RefB)),rep('F',nrow(QCF)+nrow(RefF)),rep('H',nrow(QCH)+nrow(RefH)))
    grp=c(rep('Q',nrow(QCB)),rep('R',nrow(RefB)),rep('Q',nrow(QCF)),rep('R',nrow(RefF)),rep('Q',nrow(QCH)),rep('R',nrow(RefH)))
    meta=cbind(batch,grp)

## Perform batch alignment
# Extract peakinfo (i.e. m/z and rt of features)
peakIn=peakInfo(PTnofill)

# Flag presence/missingness on batch level
bF=batchFlag(PTnofill,meta,peakIn)

# Find possible alignment candidates per sample type
aIQ=alignIndex(bF,grpType='Q',mzdiff=0.002,rtdiff=15,report=T,reportName='splits_aIQ')

# Plot achieved alignments
plotAlign(bF,aIQ,plotType='pdf',reportName='clustPlots_aIQ')

# Perform alignment -> Peaktable
bA=batchAlign(bF,aIQ,PTfill,meta)

# Extract new peak table
PT=bA$PTalign

dim(PT)

```

```{r Calculate monoisotopic mass from formula and plot isotopes}
library(enviPat)
data(isotopes)

internal_standards <- c("C9H7D5N2O", "[13]C6H12O6", "C15[13]C3H24O2",
                        "C14H10D6ClN3O", "C16[13]C3H28O2", "C16[13]C3H30O2",
                        "C19[13]C2H30D2O2", "C19H8D3F5N2O2", "C23[13]CH40O5")

chemforms_is <- check_chemform(isotopes = isotopes, chemforms = internal_standards)

pattern <- isopattern(isotopes = isotopes, chemforms = internal_standards,
                      threshold = 0.1, plotit = TRUE, charge = FALSE, algo = 1, verbose = TRUE)

isowrap(isotopes = isotopes, checked = chemforms_is, resmass = FALSE, resolution = 20000)
```